import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
# è®¾ç½®API
os.environ["OPENAI_API_KEY"] = "sk-5e030cc687b846718c190775c9ac6064"
os.environ["OPENAI_API_BASE"] = "https://api.deepseek.com"

DATA_DIR = "data/contracts"
VECTOR_DIR = "vectorstores/contracts"

st.set_page_config(
    page_title="åˆåŒæ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    layout="wide"
)

# ================= å·¥å…·å‡½æ•° =================

@st.cache_resource
def load_embeddings():
    return HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True},
    )


def load_documents():
    documents = []
    if not os.path.exists(DATA_DIR):
        os.makedirs(DATA_DIR)
        return documents

    for file in os.listdir(DATA_DIR):
        path = os.path.join(DATA_DIR, file)
        try:
            if file.lower().endswith(".pdf"):
                loader = PyPDFLoader(path)
                docs = loader.load()
            elif file.lower().endswith(".txt"):
                loader = TextLoader(path, encoding="utf-8")
                docs = loader.load()
            else:
                continue

            for d in docs:
                d.metadata["source"] = file
                documents.append(d)
        except Exception as e:
            st.error(f"åŠ è½½ {file} å¤±è´¥ï¼š{e}")

    return documents


def build_vectorstore():
    docs = load_documents()
    if not docs:
        return False, "æœªæ‰¾åˆ°åˆåŒæ–‡ä»¶"

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=150,
        separators=["\n\n", "\n", "ã€‚", "ï¼›", "ï¼Œ", " ", ""]
    )
    split_docs = splitter.split_documents(docs)

    embeddings = load_embeddings()
    vectorstore = FAISS.from_documents(split_docs, embeddings)
    os.makedirs(os.path.dirname(VECTOR_DIR), exist_ok=True)
    vectorstore.save_local(VECTOR_DIR)

    return True, f"å‘é‡åº“æ„å»ºå®Œæˆï¼ˆ{len(split_docs)} ä¸ªç‰‡æ®µï¼‰"


def ask_llm(question: str):
    embeddings = load_embeddings()
    vectorstore = FAISS.load_local(
        VECTOR_DIR,
        embeddings,
        allow_dangerous_deserialization=True
    )

    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    docs = retriever.invoke(question)

    if not docs:
        return "æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚", []

    context = "\n\n".join(
        f"æ¥æºï¼š{d.metadata.get('source')}\nå†…å®¹ï¼š{d.page_content}"
        for d in docs
    )

    llm = ChatOpenAI(
        model="deepseek-chat",
        temperature=0.3,
        max_tokens=1500
    )

    prompt = ChatPromptTemplate.from_template(
        """ä½ æ˜¯ä¸€åä¸¥è°¨çš„æ³•å¾‹åŠ©ç†ï¼Œè¯·ä¸¥æ ¼ä¾æ®ç»™å®šçš„åˆåŒå†…å®¹å›ç­”é—®é¢˜ã€‚
å¦‚æœåˆåŒä¸­æ²¡æœ‰æ˜ç¡®è¯´æ˜ï¼Œè¯·å›ç­”â€œåˆåŒä¸­æœªæ˜ç¡®çº¦å®šâ€ã€‚

ã€åˆåŒå†…å®¹ã€‘
{context}

ã€é—®é¢˜ã€‘
{question}

ã€è¦æ±‚ã€‘
- åªåŸºäºåˆåŒå†…å®¹å›ç­”
- ç”¨æ¸…æ™°ã€æ¡ç†åŒ–çš„ä¸­æ–‡
- ä¸è¦ç¼–é€ åˆåŒä¸­ä¸å­˜åœ¨çš„æ¡æ¬¾
"""
    )

    chain = prompt | llm
    answer = chain.invoke({
        "context": context,
        "question": question
    })

    return answer.content.strip(), docs


# ================= é¡µé¢ =================

st.title("ğŸ“„ åˆåŒæ™ºèƒ½é—®ç­”ç³»ç»Ÿ")

with st.sidebar:
    st.header("ğŸ“‚ åˆåŒç®¡ç†")

    if st.button("ğŸ”„ æ„å»º / æ›´æ–°å‘é‡åº“"):
        with st.spinner("æ­£åœ¨æ„å»ºå‘é‡åº“..."):
            ok, msg = build_vectorstore()
        if ok:
            st.success(msg)
        else:
            st.warning(msg)

    st.markdown("---")
    st.markdown("**ä½¿ç”¨è¯´æ˜**")
    st.markdown(
        """
        1. å°†åˆåŒ PDF / TXT æ”¾å…¥ `data/contracts`
        2. ç‚¹å‡»ã€Œæ„å»ºå‘é‡åº“ã€
        3. åœ¨å³ä¾§è¾“å…¥åˆåŒé—®é¢˜
        """
    )

# ä¸»åŒºåŸŸ
question = st.text_input("è¯·è¾“å…¥åˆåŒé—®é¢˜ï¼š", placeholder="ä¾‹å¦‚ï¼šåˆåŒçš„è¿çº¦è´£ä»»æ˜¯ä»€ä¹ˆï¼Ÿ")

if st.button("ğŸ” æŸ¥è¯¢") and question:
    if not os.path.exists(VECTOR_DIR):
        st.warning("è¯·å…ˆæ„å»ºå‘é‡åº“")
    else:
        with st.spinner("æ­£åœ¨åˆ†æåˆåŒå†…å®¹..."):
            answer, docs = ask_llm(question)

        st.subheader("âœ… ç»¼åˆç­”æ¡ˆ")
        st.write(answer)

        with st.expander("ğŸ“„ æŸ¥çœ‹å¼•ç”¨çš„åˆåŒåŸæ–‡"):
            for i, d in enumerate(docs, 1):
                st.markdown(f"**æ®µè½ {i}ï½œæ¥æºï¼š{d.metadata.get('source')}**")
                st.write(d.page_content)
                st.markdown("---")
